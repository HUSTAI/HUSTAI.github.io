const t=JSON.parse('{"key":"v-f91c4b10","path":"/zh/posts/llm/Goat.html","title":"在特定任务上微调语言模型","lang":"zh-CN","frontmatter":{"author":"shb","icon":"pen-to-square","date":"2023-06-12T00:00:00.000Z","shortTitle":"Goat","category":["语言模型"],"tag":["推理"],"star":true,"description":"在特定任务上微调语言模型 论文：Goat: Fine-tuned LLaMA Outperforms GPT-4 on Arithmetic Tasks【新加坡国立大学】 Goat模型是一个基于7B LLaMA微调的模型，在算术任务上的性能优于GPT-4，在零样本设置中还超越了75倍参数量的540B PaLM","head":[["meta",{"property":"og:url","content":"https://github.com/HUSTAI/HUSTAI.github.io/zh/posts/llm/Goat.html"}],["meta",{"property":"og:site_name","content":"知识分享"}],["meta",{"property":"og:title","content":"在特定任务上微调语言模型"}],["meta",{"property":"og:description","content":"在特定任务上微调语言模型 论文：Goat: Fine-tuned LLaMA Outperforms GPT-4 on Arithmetic Tasks【新加坡国立大学】 Goat模型是一个基于7B LLaMA微调的模型，在算术任务上的性能优于GPT-4，在零样本设置中还超越了75倍参数量的540B PaLM"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2023-06-16T02:23:19.000Z"}],["meta",{"property":"article:author","content":"shb"}],["meta",{"property":"article:tag","content":"推理"}],["meta",{"property":"article:published_time","content":"2023-06-12T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2023-06-16T02:23:19.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"在特定任务上微调语言模型\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2023-06-12T00:00:00.000Z\\",\\"dateModified\\":\\"2023-06-16T02:23:19.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"shb\\"}]}"]]},"headers":[],"git":{"createdTime":1686823822000,"updatedTime":1686882199000,"contributors":[{"name":"Liu Xiao","email":"42756849+liuxiaocs7@users.noreply.github.com","commits":2}]},"readingTime":{"minutes":1.46,"words":439},"filePathRelative":"zh/posts/llm/Goat.md","localizedDate":"2023年6月12日","excerpt":"<h1> 在特定任务上微调语言模型</h1>\\n<p>论文：Goat: Fine-tuned LLaMA Outperforms GPT-4 on Arithmetic Tasks【新加坡国立大学】</p>\\n<p>Goat模型是一个基于7B LLaMA微调的模型，在算术任务上的性能优于GPT-4，在零样本设置中还超越了75倍参数量的540B PaLM</p>\\n","autoDesc":true}');export{t as data};
