import{_ as o}from"./plugin-vue_export-helper-c27b6911.js";import{r as i,o as a,c as l,a as e,b as t,d as r}from"./app-92330e17.js";const s={},c=e("h1",{id:"instruct-prompt-tuning数据",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#instruct-prompt-tuning数据","aria-hidden":"true"},"#"),t(" Instruct/Prompt Tuning数据")],-1),h=e("h2",{id:"_1-super-natural-instruction-【allen-ai】",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#_1-super-natural-instruction-【allen-ai】","aria-hidden":"true"},"#"),t(" 1.Super-Natural Instruction 【Allen AI】")],-1),u=e("br",null,null,-1),d={href:"https://instructions.apps.allenai.org/",target:"_blank",rel:"noopener noreferrer"},_=e("h2",{id:"_2-promptsource【bigscience】",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#_2-promptsource【bigscience】","aria-hidden":"true"},"#"),t(" 2.PromptSource【BigScience】")],-1),p={href:"https://github.com/bigscience-workshop/promptsource",target:"_blank",rel:"noopener noreferrer"},g=e("br",null,null,-1),f=e("br",null,null,-1),b=e("h2",{id:"_3-p3【bigscience】",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#_3-p3【bigscience】","aria-hidden":"true"},"#"),t(" 3.P3【BigScience】")],-1),m={href:"https://huggingface.co/datasets/bigscience/P3",target:"_blank",rel:"noopener noreferrer"},k=e("br",null,null,-1),x=e("br",null,null,-1),S=e("h2",{id:"_4-xmtf-【bigscience-包含中文】",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#_4-xmtf-【bigscience-包含中文】","aria-hidden":"true"},"#"),t(" 4.xMTF 【BigScience，包含中文】")],-1),C=e("br",null,null,-1),I=e("br",null,null,-1),P={href:"https://huggingface.co/datasets/bigscience/P3",target:"_blank",rel:"noopener noreferrer"},G=e("h2",{id:"_5-hh-rlhf【anthropic】",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#_5-hh-rlhf【anthropic】","aria-hidden":"true"},"#"),t(" 5.HH-RLHF【Anthropic】")],-1),L={href:"https://github.com/anthropics/hh-rlhf",target:"_blank",rel:"noopener noreferrer"},T=e("br",null,null,-1),A=e("br",null,null,-1),B=e("br",null,null,-1),H=e("br",null,null,-1),v=e("br",null,null,-1),z=e("br",null,null,-1),M={href:"https://huggingface.co/datasets/Anthropic/hh-rlhf",target:"_blank",rel:"noopener noreferrer"},F=e("br",null,null,-1),N=e("br",null,null,-1),w={href:"https://arxiv.org/pdf/2204.05862.pdf",target:"_blank",rel:"noopener noreferrer"},y=e("h2",{id:"_6-unnatural-instruction【orhonovich】",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#_6-unnatural-instruction【orhonovich】","aria-hidden":"true"},"#"),t(" 6.Unnatural Instruction【orhonovich】")],-1),E=e("p",null,[t("使用 LLMs 自主生成 instruction 数据是 instruct-tuning 领域较为活跃的一个方向。"),e("br"),t(" Unnatural Instruction 使用 GPT3（text-davinci-002）生成了 64k 的 instruction prompt 数据。并使用同样的模型将 64k 的 prompt 进行改写，最终得到了 240k 条 instruction 数据。"),e("br"),t(" 论文中显示，在 Instruct-Tuning 中 LLMs 自主生成的 prompt 表现出了良好的效果，甚至超过了在 P3 等数据上进行微调的 T0 等模型。")],-1),R=e("h2",{id:"_7-self-instruct【yizhongw】",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#_7-self-instruct【yizhongw】","aria-hidden":"true"},"#"),t(" 7.Self-Instruct【yizhongw】")],-1),U={href:"https://github.com/yizhongw/self-instruct",target:"_blank",rel:"noopener noreferrer"},D=e("br",null,null,-1),K=e("br",null,null,-1),V=e("h2",{id:"_8-unifiedskg-【hku】",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#_8-unifiedskg-【hku】","aria-hidden":"true"},"#"),t(" 8.UnifiedSKG 【HKU】")],-1),J=e("br",null,null,-1),O={href:"https://unifiedskg.com/",target:"_blank",rel:"noopener noreferrer"},Q=e("p",null,"解决问题：做打破彼此任务之间的边界的第一次简单尝试，使得这些可以在同一个UnifiedSKG framework下进行学习并在这些任务上取得不错的结果",-1),j=e("h2",{id:"_9-flan-collection【google】",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#_9-flan-collection【google】","aria-hidden":"true"},"#"),t(" 9.Flan Collection【Google】")],-1),q={href:"https://github.com/google-research/FLAN/tree/main/flan/v2",target:"_blank",rel:"noopener noreferrer"},W=e("br",null,null,-1),X=e("h2",{id:"_10-instructdial【prakharguptaz】",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#_10-instructdial【prakharguptaz】","aria-hidden":"true"},"#"),t(" 10.InstructDial【prakharguptaz】")],-1),Y={href:"https://github.com/prakharguptaz/Instructdial/tree/main/datasets",target:"_blank",rel:"noopener noreferrer"},Z=e("br",null,null,-1),$=e("h2",{id:"_11-alpaca-【stanford】",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#_11-alpaca-【stanford】","aria-hidden":"true"},"#"),t(" 11.*Alpaca 【Stanford】")],-1),ee={href:"https://github.com/tatsu-lab/stanford_alpaca",target:"_blank",rel:"noopener noreferrer"},te=e("h2",{id:"开源可训练的代码生成模型",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#开源可训练的代码生成模型","aria-hidden":"true"},"#"),t(" 开源可训练的代码生成模型")],-1),ne=e("h3",{id:"_1-codet5【saleforce】",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#_1-codet5【saleforce】","aria-hidden":"true"},"#"),t(" 1.CodeT5【Saleforce】")],-1),re={href:"https://baike.baidu.com/item/%E6%97%A7%E9%87%91%E5%B1%B1/29211?fromModule=lemma_inlink%EF%BC%8C",target:"_blank",rel:"noopener noreferrer"},oe=e("br",null,null,-1),ie=e("br",null,null,-1),ae=e("br",null,null,-1),le=e("br",null,null,-1),se=e("br",null,null,-1),ce=e("br",null,null,-1),he=e("br",null,null,-1),ue={href:"https://link.zhihu.com/?target=https%3A//github.com/salesforce/CodeGen",target:"_blank",rel:"noopener noreferrer"},de=e("br",null,null,-1),_e=e("br",null,null,-1),pe=e("br",null,null,-1),ge=e("br",null,null,-1),fe=e("br",null,null,-1),be=e("br",null,null,-1),me=e("br",null,null,-1),ke=e("h3",{id:"_2-incoder【metaai】",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#_2-incoder【metaai】","aria-hidden":"true"},"#"),t(" 2.InCoder【MetaAI】")],-1),xe={href:"https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2204.05999",target:"_blank",rel:"noopener noreferrer"},Se=e("br",null,null,-1),Ce=e("br",null,null,-1);function Ie(Pe,Ge){const n=i("ExternalLinkIcon");return a(),l("div",null,[c,h,e("p",null,[t("这些自然语言指令清楚而完整地描述了一项任务（传统上定义为将输入字符串映射到输出字符串）。配备“理解”语言说明的模型，如果提供了任务说明，应该可以成功解决任何看不见的任务"),u,t(" 项目链接："),e("a",d,[t("https://instructions.apps.allenai.org/"),r(n)])]),_,e("p",null,[t("项目链接："),e("a",p,[t("https://github.com/bigscience-workshop/promptsource"),r(n)]),g,t(" BigScience 由 Hugging Face 和法国 CNRS，IDRIS，GENCI 等联合组织，是当下最大的开源 LLMs 组织之一。"),f,t(" BigScience 在 2021 年末开发了PromptSource项目，开源了一系列工具 toolkits，帮助研究者基于现有NLP 任务构建 prompt。截止目前，PromptSource 项目包含了 270 个 NLP 任务的超过 2000 个 prompt 模版：")]),b,e("p",null,[t("项目链接："),e("a",m,[t("https://huggingface.co/datasets/bigscience/P3"),r(n)]),k,t(" 语言：英文"),x,t(" 在promptsource基础上，BigScience 构建了 P3 数据集。在 Hugging Face Hub 上你可以找到 P3 数据，P3 的数据规模在 100M-1B 之间：")]),S,e("p",null,[t("BigScience 在英语 prompt 的基础上，扩展其 prompt 到多种非英语语言。"),C,t(" 该项目包含了 13 个 NLP 任务，并采用了 46 个不同的语言的版本。对应的 prompt 包含的语种个数不定。"),I,t(" 项目链接："),e("a",P,[t("https://huggingface.co/datasets/bigscience/P3"),r(n)])]),G,e("p",null,[t("项目链接："),e("a",L,[t("https://github.com/anthropics/hh-rlhf"),r(n)]),T,t(" 数量："),A,t(" 训练集：161k"),B,t(" 测试集：8.55k"),H,t(" Anthropic 公司旗下的 Claud 是 ChatGPT 的主要竞品之一。"),v,t(" Anthropic 开源了其在自己产品线中使用的 RLHF 数据集："),z,e("a",M,[t("https://huggingface.co/datasets/Anthropic/hh-rlhf"),r(n)]),F,t(" HH-RLHF 项目的初衷在于训练 Helpful and Harmless（HH）的 LLMs。故该项目除了回复质量外，是否为有害信息也体现在了其 human feedback 中："),N,e("a",w,[t("https://arxiv.org/pdf/2204.05862.pdf"),r(n)])]),y,E,R,e("p",null,[t("项目链接："),e("a",U,[t("https://github.com/yizhongw/self-instruct"),r(n)]),D,t(" Self-Instruct 同样是使用 LLMs 生成 prompt 进行 instruct-tuning 的思路。不过使用了更 fine-grained 的生成流程。"),K,t(" Task pool 和 Quality filtering 等概念被引入，部分缓解了 self-intrauct 类型数据的 noise 问题")]),V,e("p",null,[t("UnifiedSKG 在 Text-to-Text 的框架中加入了 knowledge grounding，也就是在 prompt-output 的框架中，加入了结构化数据做辅助，共21个任务数据集，"),J,t(" 项目主页 ："),e("a",O,[t("https://unifiedskg.com/"),r(n)])]),Q,j,e("p",null,[t("项目链接："),e("a",q,[t("https://github.com/google-research/FLAN/tree/main/flan/v2"),r(n)]),W,t(" Google 在这个项目中将自己的 Flan 2021 数据与一些开源的 instruction 数据（P3，super-natural instruction 等）进行了合并")]),X,e("p",null,[e("a",Y,[t("https://github.com/prakharguptaz/Instructdial/tree/main/datasets"),r(n)]),Z,t(" InstructDial 是在特定的一种任务类型上进行指令微调的尝试。实验结果表明，在对话指令数据上微调后，模型在对话任务上的表现强于在超大规模任务集上的结果")]),$,e("p",null,[t("项目链接:"),e("a",ee,[t("https://github.com/tatsu-lab/stanford_alpaca"),r(n)])]),te,ne,e("p",null,[t("Salesforce是创建于1999年3月的一家客户关系管理(CRM) 软件服务提供商，总部设于美国"),e("a",re,[t("https://baike.baidu.com/item/旧金山/29211?fromModule=lemma_inlink，"),r(n)]),oe,t(" 2021年9月，Saleforce公布了CodeT5模型。目前，Saleforce公开了4个版本的CodeT5模型，均开源可获得。"),ie,t(" CodeT5-small：0.6亿参数"),ae,t(" CodeT5-base：2.2亿参数"),le,t(" CodeT5-large：7.7亿参数"),se,t(" CodeT5-large-ntp-py：7.7亿参数"),ce,t(" Saleforce的CodeGen/CodeGen2"),he,e("a",ue,[t("https://link.zhihu.com/?target=https%3A//github.com/salesforce/CodeGen"),r(n)]),de,t(" 2022年5月，Saleforce再次发布了一个新的编程模型CodeGen。该模型是一系列模型，参数有4个版本：3.5亿、20亿、60亿和160亿。而训练的数据也有三个："),_e,t(" nl版本：基于Pile数据训练"),pe,t(" multi版本：在nl基础上继续在多个编程语言组成的数据集上训练"),ge,t(" mono版本：继续在multi版本上基于Python代码数据训练"),fe,t(" 上述12个模型全部在HuggingFace上开源。"),be,t(" 2023年5月3日，Saleforce开源第二代CodeGen：CodeGen2发布。该系列模型包含4个版本，分别是10亿参数、37亿参数、70亿参数和160亿参数四个版本。CodeGen2可以进行infilling，并且支持更多的编程语言。这里的infilling应该是在插入代码的含义。"),me,t(" CodeGen2也是全部开源，其中160亿参数版本开源文件大小66GB左右~")]),ke,e("p",null,[e("a",xe,[t("https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2204.05999"),r(n)]),Se,t(" InCoder是MetaAI在2022年4月发布的一个编程大模型。模型训练数据仅包含来自在线来源（如GitHub、GitLab和StackOverflow）的开放许可代码（Apache 2.0、MIT、BSD-2和BSD-3许可），其中重点是Python和JavaScript，但总共包括28种语言 - 总共约200GB的数据。公开的模型预训练结果共2个版本，一个是67亿参数一个是13亿参数。"),Ce,t(" 尽管InCoder的训练数据都是开放许可代码数据，但是MetaAI的InCoder模型确实开源的不可商用的！")])])}const Ae=o(s,[["render",Ie],["__file","Instruct和Prompt Tuning数据汇总分享.html.vue"]]);export{Ae as default};
