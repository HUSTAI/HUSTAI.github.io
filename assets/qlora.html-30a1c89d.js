import{_ as a}from"./plugin-vue_export-helper-c27b6911.js";import{o,c as t,a as e,b as r}from"./app-7cb10e98.js";const c={},s=e("h1",{id:"让微调更高效",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#让微调更高效","aria-hidden":"true"},"#"),r(" 让微调更高效")],-1),n=e("p",null,"低秩自适应（LoRA）技术可以提高微调的效率，可以在单个24GB显存GPU上对70亿参数LLaMA模型进行微调。而最近发布的一个新技术QLoRA（量化LoRA）可以在单个 48GB显存的GPU上训练650亿参数的LLaMA模型，量化的4位参数设置下，训练后得到的65B Guanaco模型保持了完整的16位微调任务性能，并且仅在微调24小时后就达到了ChatGPT性能的99.3%。",-1),_=[s,n];function d(l,i){return o(),t("div",null,_)}const m=a(c,[["render",d],["__file","qlora.html.vue"]]);export{m as default};
