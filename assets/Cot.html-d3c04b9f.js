import{_ as c}from"./plugin-vue_export-helper-c27b6911.js";import{r as i,o as s,c as h,e as d,d as t,a as e,b as o,f as p}from"./app-00f2346a.js";const l="/assets/images/prompt/cot1.png",g="/assets/images/prompt/cot2.png",f="/assets/images/prompt/cot3.png",u="/assets/images/prompt/cot4.png",_="/assets/images/prompt/cot5.png",m="/assets/images/prompt/cot6.png",b="/assets/images/prompt/cot7.png",x={},C=e("h1",{id:"chain-of-thought-思维链",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#chain-of-thought-思维链","aria-hidden":"true"},"#"),o(" Chain-of-Thought: 思维链")],-1),T=e("p",null,[o("该文介绍了 "),e("code",null,"Chain-of-Thought: 思维链"),o(" 框架，结合 "),e("code",null,"in-context"),o(", "),e("code",null,"few-shot prompting"),o(" 以及多步中间推理，通过大模型来改善数学计算、常识推理的效果。")],-1),z=e("div",{class:"hint-container tip"},[e("p",{class:"hint-container-title"},"提示"),e("p",null,[o("论文题目：Chain-of-Thought Prompting Elicits Reasoning in Large Language Models"),e("br"),o(" 作者：Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed H. Chi, Quoc V. Le, Denny Zhou"),e("br"),o(" 机构：Google")])],-1),w=p('<hr><h2 id="_1-背景介绍" tabindex="-1"><a class="header-anchor" href="#_1-背景介绍" aria-hidden="true">#</a> 1 背景介绍</h2><blockquote><p>语言模型的本质是对任意一段文本序列的概率进行建模</p></blockquote><p>用一个训练好的大语言模型求解推理任务的几种范式：</p><h3 id="_1-1-zero-shot" tabindex="-1"><a class="header-anchor" href="#_1-1-zero-shot" aria-hidden="true">#</a> 1.1 Zero-Shot</h3><figure><img src="'+l+'" alt="图1.1 Zero-Shot" width="550" tabindex="0" loading="lazy"><figcaption>图1.1 Zero-Shot</figcaption></figure><p>这里语言模型的输入就是一道数学题，连接上一个字符串 <code>The answer is</code>，然后让语言模型帮助续写。续写的答案就是80。</p><h3 id="_1-2-zero-shot-cot" tabindex="-1"><a class="header-anchor" href="#_1-2-zero-shot-cot" aria-hidden="true">#</a> 1.2 Zero-Shot-CoT</h3><figure><img src="'+g+'" alt="图1.2 Zero-Shot-CoT" width="550" tabindex="0" loading="lazy"><figcaption>图1.2 Zero-Shot-CoT</figcaption></figure><p><code>Zero-Shot-CoT</code> 在 <code>Zero-Shot</code> 的基础上增加了一句 <code>Let&#39;s think step by step.</code>，大语言模型会自动续写推理过程并得出最后的答案。</p><h3 id="_1-3-manual-cot" tabindex="-1"><a class="header-anchor" href="#_1-3-manual-cot" aria-hidden="true">#</a> 1.3 Manual-CoT</h3><figure><img src="'+f+'" alt="图1.3 Manual-CoT" width="400" tabindex="0" loading="lazy"><figcaption>图1.3 Manual-CoT</figcaption></figure><p>在输入问题之前，<strong>手动设计</strong>一些问题和答案的样例。<code>Manual-CoT</code> 比 <code>Zero-Shot-CoT</code> 的性能要好，因为在输入端提供了问题，推理，答案的样例供参考。然而为了提供这些样例就需要人工设计，这就增加了人工的成本。</p><h3 id="_1-4-auto-cot" tabindex="-1"><a class="header-anchor" href="#_1-4-auto-cot" aria-hidden="true">#</a> 1.4 Auto-CoT</h3><figure><img src="'+u+'" alt="图1.4 Auto-CoT" width="400" tabindex="0" loading="lazy"><figcaption>图1.4 Auto-CoT</figcaption></figure><p>如何将人工设计样例的过程自动化？步骤如下：<br> （1）通过多样性选择有代表性的问题<br> （2）对于每一个采样的问题，接上 <code>Let&#39;s think step by step.</code>，直接丢给语言模型，让它帮我们生成中间推理步骤和答案。然后把所有采样的问题和模型自动生成的推理步骤和答案全部拼接在一起来构成 <code>Few-Shot-Learning</code> 所需要的样例，最后跟上下面需要求解的问题，一起丢给语言模型，让其帮我们续写。</p><h2 id="_2-思路" tabindex="-1"><a class="header-anchor" href="#_2-思路" aria-hidden="true">#</a> 2 思路</h2><p>结合 <code>in-context</code>, <code>few-shot prompting</code> 以及多步中间推理，通过大模型来改善数学计算、常识推理的效果</p><figure><img src="'+_+'" alt="图2.1 CoT" width="600" tabindex="0" loading="lazy"><figcaption>图2.1 CoT</figcaption></figure><p><code>CoT</code> 思维链的灵感来源于人做推理的过程，作者借鉴了这个过程，通过设计类似于思维链来激发大模型，使之拥有推理能力，并且能由于这个有逻辑性的思维链的存在，多步的中间推到可以得到最终的正确答案。</p><figure><img src="'+m+'" alt="图2.2 CoT Examplars" width="600" tabindex="0" loading="lazy"><figcaption>图2.2 CoT Examplars</figcaption></figure><h2 id="_3-实验结果" tabindex="-1"><a class="header-anchor" href="#_3-实验结果" aria-hidden="true">#</a> 3 实验结果</h2><figure><img src="'+b+'" alt="图3.1 不同模型实验结果" width="480" tabindex="0" loading="lazy"><figcaption>图3.1 不同模型实验结果</figcaption></figure><p>100B（1000亿参数）参数量以下的模型效果不好，侧面反映了他们的instruct fine-tune不够，COT很难激发他的in-context 推理能力。而在100B以上模型效果很好，甚至超过了之前基于监督训练的SOTA模型。</p><h2 id="_4-参考" tabindex="-1"><a class="header-anchor" href="#_4-参考" aria-hidden="true">#</a> 4 参考</h2>',25),k={href:"https://zhuanlan.zhihu.com/p/610241799",target:"_blank",rel:"noopener noreferrer"},L=e("br",null,null,-1),S={href:"https://mp.weixin.qq.com/s?__biz=Mzg3Njk2NTc4Mw==&mid=2247483895&idx=1&sn=33ab2fe70af404d528f0771ae5416c87&chksm=cf2b7b0ff85cf21928bba2205f9a3b61b44486bda55947f9f6f2891a4bf6d1b3787cfbf523e5&scene=21#wechat_redirect",target:"_blank",rel:"noopener noreferrer"},B=e("br",null,null,-1),y={href:"https://zhuanlan.zhihu.com/p/617594574",target:"_blank",rel:"noopener noreferrer"};function E(M,Z){const n=i("PDF"),r=i("BiliBili"),a=i("ExternalLinkIcon");return s(),h("div",null,[C,T,d(" more "),z,t(n,{url:"https://arxiv.org/pdf/2201.11903.pdf"}),t(r,{bvid:"BV1t8411e7Ug"}),w,e("p",null,[o("[1] "),e("a",k,[o("Chain-of-Thought Prompting Elicits Reasoning in Large Language Models"),t(a)]),L,o(" [2] "),e("a",S,[o("GOOGLE | COT（chain of thought）开山之作，利用思维链提升复杂问题推理能力一、概述"),t(a)]),B,o(" [3] "),e("a",y,[o("CoT开山之作：Chain-of-Thought Prompting Elicits Reasoning in Large Language Models 论文解读"),t(a)])])])}const v=c(x,[["render",E],["__file","Cot.html.vue"]]);export{v as default};
