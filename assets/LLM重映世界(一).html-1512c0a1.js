const t=JSON.parse('{"key":"v-0c6c85b7","path":"/zh/posts/2023-06/LLM%E9%87%8D%E6%98%A0%E4%B8%96%E7%95%8C(%E4%B8%80).html","title":"LLM如何重映现实世界（一）","lang":"zh-CN","frontmatter":{"author":"bobo","icon":"pen-to-square","date":"2023-06-14T00:00:00.000Z","category":["大语言模型"],"tag":["LLM"],"star":true,"description":"LLM如何重映现实世界（一） ——LLM中的信息压缩能力与思维回路假设 知乎原文：https://zhuanlan.zhihu.com/p/632795115 版权归属原作者，如涉侵权，请联系删除 一种观点认为GPT 4 这种 LLM 模型仅仅学会了语言中的单词共现等浅层的表面统计关系，其实并未具备智能，只是类似鹦鹉学舌的语言片段缝合怪而已；另外一种观点则认为：GPT 4 不仅学会了语言元素间的表面统计关系，而且学到了人类语言甚至包括物理世界的内在运行规律，文字是由内在智能产生的，所以 LLM 具备类人智能。","head":[["meta",{"property":"og:url","content":"https://github.com/hust-404/hust-404.github.io/zh/posts/2023-06/LLM%E9%87%8D%E6%98%A0%E4%B8%96%E7%95%8C(%E4%B8%80).html"}],["meta",{"property":"og:site_name","content":"知识分享"}],["meta",{"property":"og:title","content":"LLM如何重映现实世界（一）"}],["meta",{"property":"og:description","content":"LLM如何重映现实世界（一） ——LLM中的信息压缩能力与思维回路假设 知乎原文：https://zhuanlan.zhihu.com/p/632795115 版权归属原作者，如涉侵权，请联系删除 一种观点认为GPT 4 这种 LLM 模型仅仅学会了语言中的单词共现等浅层的表面统计关系，其实并未具备智能，只是类似鹦鹉学舌的语言片段缝合怪而已；另外一种观点则认为：GPT 4 不仅学会了语言元素间的表面统计关系，而且学到了人类语言甚至包括物理世界的内在运行规律，文字是由内在智能产生的，所以 LLM 具备类人智能。"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2023-06-14T08:08:27.000Z"}],["meta",{"property":"article:author","content":"bobo"}],["meta",{"property":"article:tag","content":"LLM"}],["meta",{"property":"article:published_time","content":"2023-06-14T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2023-06-14T08:08:27.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"LLM如何重映现实世界（一）\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2023-06-14T00:00:00.000Z\\",\\"dateModified\\":\\"2023-06-14T08:08:27.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"bobo\\"}]}"]]},"headers":[{"level":2,"title":"1.1 什么是NTP任务","slug":"_1-1-什么是ntp任务","link":"#_1-1-什么是ntp任务","children":[]},{"level":2,"title":"1.2 利用 LLM 进行数据压缩","slug":"_1-2-利用-llm-进行数据压缩","link":"#_1-2-利用-llm-进行数据压缩","children":[]},{"level":2,"title":"1.3 压缩即智能","slug":"_1-3-压缩即智能","link":"#_1-3-压缩即智能","children":[]}],"git":{"createdTime":1686730107000,"updatedTime":1686730107000,"contributors":[{"name":"Sun","email":"57407733+shbone@users.noreply.github.com","commits":1}]},"readingTime":{"minutes":6.62,"words":1986},"filePathRelative":"zh/posts/2023-06/LLM重映世界(一).md","localizedDate":"2023年6月14日","excerpt":"<h1> LLM如何重映现实世界（一）</h1>\\n<h1> ——LLM中的信息压缩能力与思维回路假设</h1>\\n<blockquote>\\n<p>知乎原文：<a href=\\"https://zhuanlan.zhihu.com/p/632795115\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">https://zhuanlan.zhihu.com/p/632795115</a><br>\\n版权归属原作者，如涉侵权，请联系删除</p>\\n</blockquote>\\n<p>一种观点认为GPT 4 这种 LLM 模型仅仅学会了语言中的单词共现等浅层的表面统计关系，其实并未具备智能，只是类似鹦鹉学舌的语言片段缝合怪而已；另外一种观点则认为：GPT 4 不仅学会了语言元素间的表面统计关系，而且学到了人类语言甚至包括物理世界的内在运行规律，文字是由内在智能产生的，所以 LLM 具备类人智能。</p>","autoDesc":true}');export{t as data};
