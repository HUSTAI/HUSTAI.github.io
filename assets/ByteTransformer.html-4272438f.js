const t=JSON.parse('{"key":"v-dd8a63b2","path":"/zh/posts/2023-06/ByteTransformer.html","title":"ByteTransformer","lang":"zh-CN","frontmatter":{"author":"章陆军","icon":"pen-to-square","date":"2023-06-12T00:00:00.000Z","category":["transformer"],"tag":["优化","nvidia","字节"],"sticky":10,"description":"ByteTransformer 20230605汇报-bytetransformer 论文地址：https://arxiv.org/abs/2210.03052 代码地址：https://github.com/bytedance/ByteTransformer contribution： ●我们设计和开发了 ByteTransformer，这是一种针对可变长度输入优化的高性能 GPU 加速转换器。 ByteTransformer 已部署服务于包括字节跳动的 TikTok 和抖音在内的世界级应用 ●我们提出了一种padding-free算法，将输入张量与可变长度序列打包，并计算所有变换器操作的定位偏移向量以进行索引，从而使整个变换器管道免于填充和计算零令牌 ●我们提出了一个Fused Multi-Head Attention来减轻中间矩阵的内存开销，中间矩阵是序列长度的二次方，在 MHA 中没有引入由于填充可变长度输入而导致的冗余计算。我们融合的 MHA 的一部分已经部署在 NVIDIA CUTLASS 的生产代码库中","head":[["meta",{"property":"og:url","content":"https://github.com/hust-404/hust-404.github.io/zh/posts/2023-06/ByteTransformer.html"}],["meta",{"property":"og:site_name","content":"知识分享"}],["meta",{"property":"og:title","content":"ByteTransformer"}],["meta",{"property":"og:description","content":"ByteTransformer 20230605汇报-bytetransformer 论文地址：https://arxiv.org/abs/2210.03052 代码地址：https://github.com/bytedance/ByteTransformer contribution： ●我们设计和开发了 ByteTransformer，这是一种针对可变长度输入优化的高性能 GPU 加速转换器。 ByteTransformer 已部署服务于包括字节跳动的 TikTok 和抖音在内的世界级应用 ●我们提出了一种padding-free算法，将输入张量与可变长度序列打包，并计算所有变换器操作的定位偏移向量以进行索引，从而使整个变换器管道免于填充和计算零令牌 ●我们提出了一个Fused Multi-Head Attention来减轻中间矩阵的内存开销，中间矩阵是序列长度的二次方，在 MHA 中没有引入由于填充可变长度输入而导致的冗余计算。我们融合的 MHA 的一部分已经部署在 NVIDIA CUTLASS 的生产代码库中"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2023-06-12T16:49:11.000Z"}],["meta",{"property":"article:author","content":"章陆军"}],["meta",{"property":"article:tag","content":"优化"}],["meta",{"property":"article:tag","content":"nvidia"}],["meta",{"property":"article:tag","content":"字节"}],["meta",{"property":"article:published_time","content":"2023-06-12T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2023-06-12T16:49:11.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"ByteTransformer\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2023-06-12T00:00:00.000Z\\",\\"dateModified\\":\\"2023-06-12T16:49:11.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"章陆军\\"}]}"]]},"headers":[],"git":{"createdTime":1686588551000,"updatedTime":1686588551000,"contributors":[{"name":"Liu Xiao","email":"42756849+liuxiaocs7@users.noreply.github.com","commits":1}]},"readingTime":{"minutes":5.71,"words":1714},"filePathRelative":"zh/posts/2023-06/ByteTransformer.md","localizedDate":"2023年6月12日","excerpt":"<h1> ByteTransformer</h1>\\n<p>20230605汇报-bytetransformer</p>\\n<p>论文地址：<a href=\\"https://arxiv.org/abs/2210.03052\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">https://arxiv.org/abs/2210.03052</a><br>\\n代码地址：<a href=\\"https://github.com/bytedance/ByteTransformer\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">https://github.com/bytedance/ByteTransformer</a></p>\\n<p>contribution：<br>\\n●我们设计和开发了 ByteTransformer，这是一种针对可变长度输入优化的高性能 GPU 加速转换器。 ByteTransformer 已部署服务于包括字节跳动的 TikTok 和抖音在内的世界级应用<br>\\n●我们提出了一种padding-free算法，将输入张量与可变长度序列打包，并计算所有变换器操作的定位偏移向量以进行索引，从而使整个变换器管道免于填充和计算零令牌<br>\\n●我们提出了一个Fused Multi-Head Attention来减轻中间矩阵的内存开销，中间矩阵是序列长度的二次方，在 MHA 中没有引入由于填充可变长度输入而导致的冗余计算。我们融合的 MHA 的一部分已经部署在 NVIDIA CUTLASS 的生产代码库中</p>\\n","autoDesc":true}');export{t as data};
