import{_ as n}from"./plugin-vue_export-helper-c27b6911.js";import{r as i,o as m,c as r,e as p,a as s,b as a,d as l,f as e}from"./app-48bd2458.js";const c="/assets/images/token/LLMretrieval1.png",o="/assets/images/token/LLMretrieval2.png",h="/assets/images/token/LLMretrieval3.png",g="/assets/images/token/LLMretrieval4.png",u="/assets/images/token/LLMretrieval5.png",d={},y=s("h1",{id:"如何通过大模型实现外挂知识库优化",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#如何通过大模型实现外挂知识库优化","aria-hidden":"true"},"#"),a(" 如何通过大模型实现外挂知识库优化")],-1),v=s("p",null,[a("大模型时代，通常采用向量召回的方式从文档库里召回和用户问题相关的文档片段，输入到LLM中来增强模型回答质量。本文分享两篇通过大模型的能力增强召回效果的文章，这两篇文章的内容都已经加入了langchain的标准组件，但是"),s("strong",null,"都有一些特定的使用场景"),a("。")],-1),f={href:"https://arxiv.org/abs/2212.10496",target:"_blank",rel:"noopener noreferrer"},_=s("br",null,null,-1),b={href:"https://arxiv.org/abs/2305.06983",target:"_blank",rel:"noopener noreferrer"},k=s("br",null,null,-1),L={href:"https://zhuanlan.zhihu.com/p/653808554",target:"_blank",rel:"noopener noreferrer"},x=e('<h2 id="_1-hyde-1" tabindex="-1"><a class="header-anchor" href="#_1-hyde-1" aria-hidden="true">#</a> 1 HYDE[1]</h2><h3 id="_1-1-框架介绍" tabindex="-1"><a class="header-anchor" href="#_1-1-框架介绍" aria-hidden="true">#</a> 1.1 框架介绍</h3><p>这篇文章是篇纯讨论召回的文章，最后的衡量指标也是nDCG和召回率这些指标，使用LLM单纯是为了提高召回效果的。</p><figure><img src="'+c+'" alt="图1.1 HYDE框架图" tabindex="0" loading="lazy"><figcaption>图1.1 HYDE框架图</figcaption></figure><p>论文思路非常简单：</p><ul><li>Step1: 用LLM根据用户query生成k个“假答案”。</li><li>Step2: 利用向量化模型，将生成的k的假答案和用户的query变成向量。</li><li>Step3: 根据公式1.1，将k+1个向量取平均：其中dk为第k个生成的答案，q为用户问题，f为向量化操作。</li></ul>',6),z=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mtable",{width:"100%"},[s("mtr",null,[s("mtd",{width:"50%"}),s("mtd",null,[s("mrow",null,[s("msub",null,[s("mover",{accent:"true"},[s("mi",{mathvariant:"bold"},"v"),s("mo",null,"^")]),s("msub",null,[s("mi",null,"q"),s("mrow",null,[s("mi",null,"i"),s("mi",null,"j")])])]),s("mo",null,"="),s("mfrac",null,[s("mn",null,"1"),s("mrow",null,[s("mi",null,"N"),s("mo",null,"+"),s("mn",null,"1")])]),s("mrow",null,[s("mo",{fence:"true"},"["),s("munderover",null,[s("mo",null,"∑"),s("mrow",null,[s("mi",null,"k"),s("mo",null,"="),s("mn",null,"1")]),s("mi",null,"N")]),s("mi",null,"f"),s("mrow",null,[s("mo",{fence:"true"},"("),s("msub",null,[s("mover",{accent:"true"},[s("mi",null,"d"),s("mo",null,"^")]),s("mi",null,"k")]),s("mo",{fence:"true"},")")]),s("mo",null,"+"),s("mi",null,"f"),s("mrow",null,[s("mo",{fence:"true"},"("),s("msub",null,[s("mi",null,"q"),s("mrow",null,[s("mi",null,"i"),s("mi",null,"j")])]),s("mo",{fence:"true"},")")]),s("mo",{fence:"true"},"]")])])]),s("mtd",{width:"50%"}),s("mtd",null,[s("mtext",null,"(1.1)")])])]),s("annotation",{encoding:"application/x-tex"}," \\hat{\\mathbf{v}}_{q_{i j}}=\\frac{1}{N+1}\\left[\\sum_{k=1}^{N} f\\left(\\hat{d}_{k}\\right)+f\\left(q_{i j}\\right)\\right] \\tag {1.1} ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.0552em","vertical-align":"-0.3473em"}}),s("span",{class:"mord"},[s("span",{class:"mord accent"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7079em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathbf",style:{"margin-right":"0.01597em"}},"v")]),s("span",{style:{top:"-3.0134em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"accent-body",style:{left:"-0.2222em"}},[s("span",{class:"mord"},"^")])])])])])]),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1514em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.016em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03588em"}},"q"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3281em"}},[s("span",{style:{top:"-2.357em","margin-left":"-0.0359em","margin-right":"0.0714em"}},[s("span",{class:"pstrut",style:{height:"2.5em"}}),s("span",{class:"sizing reset-size3 size1 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.05724em"}},"ij")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2819em"}},[s("span")])])])])])])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3473em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"3.1304em","vertical-align":"-1.3021em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.3214em"}},[s("span",{style:{top:"-2.314em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.10903em"}},"N"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord"},"1")])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.677em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},"1")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.7693em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"minner"},[s("span",{class:"mopen delimcenter",style:{top:"0em"}},[s("span",{class:"delimsizing size4"},"[")]),s("span",{class:"mop op-limits"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.8283em"}},[s("span",{style:{top:"-1.8479em","margin-left":"0em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03148em"}},"k"),s("span",{class:"mrel mtight"},"="),s("span",{class:"mord mtight"},"1")])])]),s("span",{style:{top:"-3.05em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",null,[s("span",{class:"mop op-symbol large-op"},"∑")])]),s("span",{style:{top:"-4.3em","margin-left":"0em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.10903em"}},"N")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.3021em"}},[s("span")])])])]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em"}},"f"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"minner"},[s("span",{class:"mopen delimcenter",style:{top:"0em"}},[s("span",{class:"delimsizing size2"},"(")]),s("span",{class:"mord"},[s("span",{class:"mord accent"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.9579em"}},[s("span",{style:{top:"-3em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord mathnormal"},"d")]),s("span",{style:{top:"-3.2634em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"accent-body",style:{left:"-0.0833em"}},[s("span",{class:"mord"},"^")])])])])])]),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3361em"}},[s("span",{style:{top:"-2.55em","margin-left":"0em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03148em"}},"k")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mclose delimcenter",style:{top:"0em"}},[s("span",{class:"delimsizing size2"},")")])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10764em"}},"f"),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"minner"},[s("span",{class:"mopen delimcenter",style:{top:"0em"}},"("),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"q"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3117em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0359em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.05724em"}},"ij")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2861em"}},[s("span")])])])])]),s("span",{class:"mclose delimcenter",style:{top:"0em"}},")")]),s("span",{class:"mclose delimcenter",style:{top:"0em"}},[s("span",{class:"delimsizing size4"},"]")])])]),s("span",{class:"tag"},[s("span",{class:"strut",style:{height:"3.1304em","vertical-align":"-1.3021em"}}),s("span",{class:"mord text"},[s("span",{class:"mord"},"("),s("span",{class:"mord"},[s("span",{class:"mord"},"1.1")]),s("span",{class:"mord"},")")])])])])])],-1),w=s("ul",null,[s("li",null,"Step4: 利用融合向量v从文档库中召回答案。融合向量中既有用户问题的信息，也有想要答案的模式信息，可以增强召回效果。")],-1),M=s("h3",{id:"_1-2-实验结果",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#_1-2-实验结果","aria-hidden":"true"},"#"),a(" 1.2 实验结果")],-1),q=s("p",null,"模型有上标FT指的是向量化模型在TREC DL相关的数据集上微调过的。黄框标出来的是未使用hyde技术的baseline结果。绿框标出来的是未微调的向量化模型使用hyde技术的实验结果。红框标出来的是微调过的向量化模型使用hyde技术的实验结果。",-1),N=s("figure",null,[s("img",{src:o,alt:"表1.1 实验结果",tabindex:"0",loading:"lazy"}),s("figcaption",null,"表1.1 实验结果")],-1),D=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mtable",{width:"100%"},[s("mtr",null,[s("mtd",{width:"50%"}),s("mtd",null,[s("mrow",null,[s("mi",null,"N"),s("mi",null,"D"),s("mi",null,"C"),s("mi",null,"G"),s("mi",{mathvariant:"normal"},"@"),s("mi",null,"n"),s("mo",null,"="),s("mfrac",null,[s("mn",null,"1"),s("mi",null,"N")]),s("munderover",null,[s("mo",null,"∑"),s("mrow",null,[s("mi",null,"i"),s("mo",null,"="),s("mn",null,"1")]),s("mi",null,"n")]),s("mfrac",null,[s("mi",null,"G"),s("mi",null,"D")])])]),s("mtd",{width:"50%"}),s("mtd",null,[s("mtext",null,"(1.2)")])])]),s("annotation",{encoding:"application/x-tex"}," N D C G @ n=\\frac{1}{N} \\sum_{i=1}^{n} \\frac{G}{D} \\tag {1.2} ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6944em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.10903em"}},"N"),s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"D"),s("span",{class:"mord mathnormal"},"CG"),s("span",{class:"mord"},"@"),s("span",{class:"mord mathnormal"},"n"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"2.9291em","vertical-align":"-1.2777em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.3214em"}},[s("span",{style:{top:"-2.314em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.10903em"}},"N")])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.677em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord"},"1")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.686em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mop op-limits"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.6514em"}},[s("span",{style:{top:"-1.8723em","margin-left":"0em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"i"),s("span",{class:"mrel mtight"},"="),s("span",{class:"mord mtight"},"1")])])]),s("span",{style:{top:"-3.05em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",null,[s("span",{class:"mop op-symbol large-op"},"∑")])]),s("span",{style:{top:"-4.3em","margin-left":"0em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"n")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.2777em"}},[s("span")])])])]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mopen nulldelimiter"}),s("span",{class:"mfrac"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.3603em"}},[s("span",{style:{top:"-2.314em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"D")])]),s("span",{style:{top:"-3.23em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"frac-line",style:{"border-bottom-width":"0.04em"}})]),s("span",{style:{top:"-3.677em"}},[s("span",{class:"pstrut",style:{height:"3em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal"},"G")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.686em"}},[s("span")])])])]),s("span",{class:"mclose nulldelimiter"})])]),s("span",{class:"tag"},[s("span",{class:"strut",style:{height:"2.9291em","vertical-align":"-1.2777em"}}),s("span",{class:"mord text"},[s("span",{class:"mord"},"("),s("span",{class:"mord"},[s("span",{class:"mord"},"1.2")]),s("span",{class:"mord"},")")])])])])])],-1),C=e('<p>实验指标为NDCG@10，可以发现，对于没有微调过的向量户化模型（zero shot场景），hyde还是非常有用的，并且随着使用的LLM模型的增大，效果不断变好（因为LLM的回答质量提高了）。因为领域微调过的向量化模型性能已经不错了，NDCG@10指标能达到60多，<strong>LLM生成的假答案的知识性错误带来的负面影响大于回答模式信息带来的正面影响。</strong></p><h2 id="_2-flare-2" tabindex="-1"><a class="header-anchor" href="#_2-flare-2" aria-hidden="true">#</a> 2 FLARE[2]</h2><p>和上一篇文章相比，FLARE论文评估的指标是直接看最后LLM的回答效果的，而非是向第一篇文章那样只讨论召回准确率。这篇文章涉及到针对同一个问题的<strong>多次召回</strong>，因此比较适合长文本回答。对于大模型外挂知识库，大家通常的做法是根据用户query一次召回文档片段，让模型生成答案。只进行一次文档召回在长文本生成的场景下效果往往不好，生成的文本过长，更有可能扩展出和query相关性较弱的内容，如果模型没有这部分知识，容易产生模型幻觉问题。一种解决思路是随着文本生成，多次从向量库中召回内容。<br> 有三种常用的多次召回策略：</p><ul><li>a. 每生成固定的n个token就召回一次。</li><li>b. 每生成一个完整的句子就召回一次。</li><li>c. 将用户query一步步分解为子问题，需要解答当前子问题时候，就召回一次。</li></ul><p>已有的多次召回方案比较被动，召回文档的目的是为了得到模型不知道的信息，a、b策略并不能保证不需要召回的时候不召回，需要召回的时候触发召回。c.方案需要设计特定的prompt工程，限制了其通用性。作者在本文里提出了两种更主动的多次召回策略，让模型自己决定啥时候触发召回操作。</p><h3 id="_2-1-策略1-让模型自己决定" tabindex="-1"><a class="header-anchor" href="#_2-1-策略1-让模型自己决定" aria-hidden="true">#</a> 2.1 策略1-让模型自己决定</h3><p>通过设计prompt以及提供示例的方式，让模型知道当遇到需要查询知识的时候，提出问题，并按照格式输出，和toolformer的模式类似。<strong>提出问题的格式为[Search(“模型自动提出的问题”)]</strong>。利用模型生成的问题去召回答案。召回出答案后，将答案放到用户query的前边，然后去掉主动召回标识之后，继续生成。当下一次生成主动召回标识之后，将上一次召回出来的内容从prompt中去掉。下图展示了生成拜登相关答案时，触发多次召回的例子，分别面对拜登在哪上学和获得了什么学位的知识点上进行了主动召回标识的生成。</p><figure><img src="'+h+'" alt="图2.1 策略1示意图" tabindex="0" loading="lazy"><figcaption>图2.1 策略1示意图</figcaption></figure><p>该方法也存在一些缺陷：</p><ul><li>1.LLM不愿意生成主动召回标识。解决方法：对&quot;[&quot;对应的logit乘2，增加生成&quot;[&quot;的概率，&quot;[&quot;为主动召回标识的第一个字，进而促进主动召回标识的生成。</li><li>2.过于频繁的主动召回可能会影响生成质量。解决方法：在刚生成一次主动召回标识、得到召回后的文档、去掉主动召回标识之后，接下来生成的几个token禁止生成&quot;[&quot;。</li><li>3.不微调该方案不太可靠，很难通过few shot的方式让模型生成这种输出模式。</li></ul><h3 id="_2-2-策略2-根据模型生成的token决定" tabindex="-1"><a class="header-anchor" href="#_2-2-策略2-根据模型生成的token决定" aria-hidden="true">#</a> 2.2 策略2-根据模型生成的token决定</h3><p>策略1存在的第3点缺陷比较知名。因此作者提出了另外一个策略。该策略基于一个假设：模型生成的词对应该的概率能够表现生成内容的置信度。（传统的chatgpt接口是用不了策略2的，因为得不到生成每个词的概率。）<br> 分为4个步骤：</p><ul><li>Step0:根据用户的query，进行第一次召回，让模型生成答案。</li><li>Step1:之后，每生成64个token，用NLTK工具包从64个token里边找到第一个完整句子，当作“假答案”，扔掉多余的token。（和第一篇文章思想一样，利用LLM生成符合回答模式的“假答案”）</li><li>Step2:如果“假答案”里有任意一个token对应的概率，低于某一阈值，那么就利用这个句子进行向量召回。将“假答案”中生成概率低于某一阈值的token扔掉（低概率的token很有可能存在错误信息），然后再进行向量召回。</li><li>Step3:利用召回出来的文本，重新生成新的“真答案”，然后进行下一个句子的生成。</li></ul><p>依然针对拜登的问题，下图给出了例子。</p><figure><img src="'+g+'" alt="图2.2 策略2示意图" tabindex="0" loading="lazy"><figcaption>图2.2 策略2示意图</figcaption></figure><p>接下来介绍一下实验结果。先声明一下，这篇文章用的召回器（向量化模型）是BM25，2009年被提出，基于统计学的原理，属于一种词袋模型，效果一般。如果用一些效果更好的基于神经网络的召回器，本文提出的方法提升就没那么大了。</p><figure><img src="'+u+'" alt="图2.3 实验结果" tabindex="0" loading="lazy"><figcaption>图2.3 实验结果</figcaption></figure><h2 id="_3-参考" tabindex="-1"><a class="header-anchor" href="#_3-参考" aria-hidden="true">#</a> 3 参考</h2><p>[1] Luyu Gao, Xueguang Ma, Jimmy Lin, Jamie Callan. Precise Zero-Shot Dense Retrieval without Relevance Labels. In: Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (ACL 2023), Toronto, Canada, July 9-14, 2023, ACL, 2023: 1762–1777<br> [2] Zhengbao Jiang, Frank F. Xu, Luyu Gao, Zhiqing Sun, Qian Liu, Jane Dwivedi-Yu, et al. Active Retrieval Augmented Generation. arXiv, 2023</p>',19);function G(S,E){const t=i("ExternalLinkIcon");return m(),r("div",null,[y,v,p(" more "),s("p",null,[a("HYDE："),s("a",f,[a("https://arxiv.org/abs/2212.10496"),l(t)]),_,a(" FLARE："),s("a",b,[a("https://arxiv.org/abs/2305.06983"),l(t)]),k,a(" 知乎："),s("a",L,[a("https://zhuanlan.zhihu.com/p/653808554"),l(t)])]),x,z,w,M,q,N,D,C])}const j=n(d,[["render",G],["__file","LLMretrieval.html.vue"]]);export{j as default};
