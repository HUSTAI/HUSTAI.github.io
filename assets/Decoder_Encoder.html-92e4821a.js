import{_ as n}from"./plugin-vue_export-helper-c27b6911.js";import{o as a,c as s,e as o,a as e,b as t,f as c}from"./app-6f4bc68f.js";const r="/assets/images/llm/coder_1.png",d="/assets/images/llm/coder_2.png",i="/assets/images/llm/coder_3.png",p={},l=e("h1",{id:"基于encoder和decoder的三种架构",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#基于encoder和decoder的三种架构","aria-hidden":"true"},"#"),t(" 基于Encoder和Decoder的三种架构")],-1),u=e("p",null,"Transformer由论文《Attention is All You Need》提出，现在是谷歌云TPU推荐的参考模型。论文相关的Tensorflow的代码可以从GitHub获取，其作为Tensor2Tensor包的一部分。哈佛的NLP团队也实现了一个基于PyTorch的版本，并注释该论文。",-1),h=c('<h2 id="_1-encoder-decoder" tabindex="-1"><a class="header-anchor" href="#_1-encoder-decoder" aria-hidden="true">#</a> 1 Encoder-Decoder</h2><figure><img src="'+r+'" alt="示意图" tabindex="0" loading="lazy"><figcaption>图1.1 语言模型进化树</figcaption></figure><p>其中Encoder单层包括Self-Attention和MLP，Decoder单层包括Self-Attention，Cross-Attention和MLP。<br> Cross-Attention的特殊之处在于输入的K和V来自Encoder的输出，而Q来自于自己的Self-Attention的输出。</p><figure><img src="'+d+'" alt="示意图" tabindex="0" loading="lazy"><figcaption>图1.2 标准transformer架构</figcaption></figure><figure><img src="'+i+`" alt="示意图" tabindex="0" loading="lazy"><figcaption>图1.3 Encoder的输出流向</figcaption></figure><h2 id="_1-1-t5" tabindex="-1"><a class="header-anchor" href="#_1-1-t5" aria-hidden="true">#</a> 1.1 T5</h2><p>T5模型的Encoder和Decoder区分的比较明确，在定义时就给出了。</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>encoder_config <span class="token operator">=</span> copy<span class="token punctuation">.</span>deepcopy<span class="token punctuation">(</span>config<span class="token punctuation">)</span>
encoder_config<span class="token punctuation">.</span>is_decoder <span class="token operator">=</span> <span class="token boolean">False</span>
encoder_config<span class="token punctuation">.</span>use_cache <span class="token operator">=</span> <span class="token boolean">False</span>
encoder_config<span class="token punctuation">.</span>is_encoder_decoder <span class="token operator">=</span> <span class="token boolean">False</span>
self<span class="token punctuation">.</span>encoder <span class="token operator">=</span> T5Stack<span class="token punctuation">(</span>encoder_config<span class="token punctuation">,</span> self<span class="token punctuation">.</span>shared<span class="token punctuation">)</span>

decoder_config <span class="token operator">=</span> copy<span class="token punctuation">.</span>deepcopy<span class="token punctuation">(</span>config<span class="token punctuation">)</span>
decoder_config<span class="token punctuation">.</span>is_decoder <span class="token operator">=</span> <span class="token boolean">True</span>
decoder_config<span class="token punctuation">.</span>is_encoder_decoder <span class="token operator">=</span> <span class="token boolean">False</span>
decoder_config<span class="token punctuation">.</span>num_layers <span class="token operator">=</span> config<span class="token punctuation">.</span>num_decoder_layers
self<span class="token punctuation">.</span>decoder <span class="token operator">=</span> T5Stack<span class="token punctuation">(</span>decoder_config<span class="token punctuation">,</span> self<span class="token punctuation">.</span>shared<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_1-2-chatglm" tabindex="-1"><a class="header-anchor" href="#_1-2-chatglm" aria-hidden="true">#</a> 1.2 ChatGLM</h3><p>ChatGLM之所以是Decoder-Encoder架构，并非是由于结构的原因，而在于它的功能设计，事实上，ChatGLM的所有layer结构一致，并没有Encoder，Decoder之分。</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>&lt;输入&gt;&lt;gmask&gt;&lt;bos&gt;&lt;输出&gt;&lt;eos&gt;
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>特殊之处在于它的Attention mask，自开始直到gmask是一部分，自bos直到eos是另一部分，被分为两大部分，其中第一部分具有双向特性，左右的token都会影响模型对中间token的预测，符合类Bert模型的MaskLM的特性，因此偏向于Encoder自然语言理解的功能；而第二部分只是单向特性，仅左边token会影响模型对中间token的预测，而右边的不会，符合类GPT模型的AutoRegressiveLM的特性，因此偏向于Decoder自然语言生成的功能。</p><h2 id="_2-encoder-only" tabindex="-1"><a class="header-anchor" href="#_2-encoder-only" aria-hidden="true">#</a> 2 Encoder-only</h2><p>多个只有Self-Attention和mlp的Transformer层串联起来。</p><h2 id="_3-decoder-only" tabindex="-1"><a class="header-anchor" href="#_3-decoder-only" aria-hidden="true">#</a> 3 Decoder-only</h2><p>Decoder-only架构有两大与Encoder-only架构相区别的特征。</p><p>（1）Cross-Attention：具有能接受Encoder输出的Cross-Attention作为中间层。</p><p>（2）past_key_values：在进行生成任务时，可以直接在Decoder的每一个layer内的Self-Attention添加上一步key和value，进行concate然后计算Self-Attention。</p><p>特征（1）发挥作用的时间在于Encoder计算完成后，Decoder计算过程中。特征（2）发挥作用的时间在于生成任务的循环中第2轮及以后Decoder的计算过程中。</p><h3 id="_3-1-gpt2" tabindex="-1"><a class="header-anchor" href="#_3-1-gpt2" aria-hidden="true">#</a> 3.1 GPT2</h3><p>既有特征（1）又有特征（2），但是特征（1）的使用需要用户从一开始传入Encoder层的结果，也就是只有接受Encoder输出的Cross-Attention，但自己没有产生Encoder输出的能力。当用户不提供Encoder的output时，Cross-Attention模块的计算就会被跳过。</p><h3 id="_3-2-bloom" tabindex="-1"><a class="header-anchor" href="#_3-2-bloom" aria-hidden="true">#</a> 3.2 Bloom</h3><p>只有特征（2）。</p><h3 id="_3-3-llama" tabindex="-1"><a class="header-anchor" href="#_3-3-llama" aria-hidden="true">#</a> 3.3 Llama</h3><p>只有特征（2）。</p><h2 id="_4-总结" tabindex="-1"><a class="header-anchor" href="#_4-总结" aria-hidden="true">#</a> 4 总结</h2><p>其实对Decoder-only和Encoder-only这两种，在Transformer的结构上已经近乎没有什么区别，Decoder最标志性的Cross-Attention往往不发挥作用甚至不存在。相比结构，更重要的是功能上的区别，即语义理解是双向性的还是单向性的，所做的任务是NLU还是NLG，Attention mask是对称阵还是上三角矩阵，这里才是决定一个模型所采用的架构的关键所在。</p>`,27);function _(m,f){return a(),s("div",null,[l,u,o(" more "),h])}const b=n(p,[["render",_],["__file","Decoder_Encoder.html.vue"]]);export{b as default};
