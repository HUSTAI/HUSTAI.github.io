import { HTMLMediaProvider, canUseVideoPresentation, canUsePictureInPicture, canPlayHLSNatively } from './chunk-XBYQR33W.js';
import { isNull, deferredPromise, isString, EventsTarget, DOMEvent, isNumber, onDispose, listenEvent } from './chunk-BFUJ5USN.js';

// src/player/core/tracks/text/symbols.ts
var ATTACH_VIDEO = Symbol("ATTACH_VIDEO" );
var TEXT_TRACK_CROSSORIGIN = Symbol("TEXT_TRACK_CROSSORIGIN" );
var TEXT_TRACK_READY_STATE = Symbol("TEXT_TRACK_READY_STATE" );
var TEXT_TRACK_UPDATE_ACTIVE_CUES = Symbol("TEXT_TRACK_UPDATE_ACTIVE_CUES" );
var TEXT_TRACK_CAN_LOAD = Symbol("TEXT_TRACK_CAN_LOAD" );
var TEXT_TRACK_ON_MODE_CHANGE = Symbol("TEXT_TRACK_ON_MODE_CHANGE" );
var TEXT_TRACK_NATIVE = Symbol("TEXT_TRACK_NATIVE" );
var TEXT_TRACK_NATIVE_HLS = Symbol("TEXT_TRACK_NATIVE_HLS" );

// src/utils/network.ts
function preconnect(url, rel = "preconnect") {
  const exists = document.querySelector(`link[href="${url}"]`);
  if (!isNull(exists))
    return true;
  const link = document.createElement("link");
  link.rel = rel;
  link.href = url;
  link.crossOrigin = "true";
  document.head.append(link);
  return true;
}
var pendingRequests = {};
function loadScript(src) {
  if (pendingRequests[src])
    return pendingRequests[src].promise;
  const promise = deferredPromise(), exists = document.querySelector(`script[src="${src}"]`);
  if (!isNull(exists)) {
    promise.resolve();
    return promise.promise;
  }
  const script = document.createElement("script");
  script.src = src;
  script.onload = () => {
    promise.resolve();
    delete pendingRequests[src];
  };
  script.onerror = () => {
    promise.reject();
    delete pendingRequests[src];
  };
  setTimeout(() => document.head.append(script), 0);
  return promise.promise;
}
function getRequestCredentials(crossorigin) {
  return crossorigin === "use-credentials" ? "include" : isString(crossorigin) ? "same-origin" : void 0;
}

// src/player/core/tracks/text/utils.ts
function findActiveCue(time, cues) {
  for (let i = 0, len = cues.length; i < len; i++) {
    if (isCueActive(cues[i], time))
      return cues[i];
  }
  return null;
}
function isCueActive(cue, time) {
  return time >= cue.startTime && time < cue.endTime;
}
function onTrackChapterChange(tracks, currentTrack, onChange) {
  const track = tracks.toArray().find((track2) => track2.kind === "chapters" && track2.mode === "showing");
  if (track === currentTrack)
    return;
  if (!track) {
    onChange(null);
    return;
  }
  if (track.readyState == 2) {
    onChange(track);
  } else {
    onChange(null);
    track.addEventListener("load", () => onChange(track), { once: true });
  }
}

// src/player/core/tracks/text/text-track.ts
var _a, _b, _c;
var TextTrack = class extends EventsTarget {
  constructor(init) {
    super();
    this.id = "";
    this.label = "";
    this.language = "";
    this.default = false;
    this._canLoad = false;
    this._currentTime = 0;
    this._mode = "disabled";
    this._metadata = {};
    this._regions = [];
    this._cues = [];
    this._activeCues = [];
    /* @internal */
    this[_a] = 0;
    /* @internal */
    this[_b] = null;
    /* @internal */
    this[_c] = null;
    for (const prop of Object.keys(init))
      this[prop] = init[prop];
    if (init.content) {
      import('./dev-DOQY4JGU.js').then(({ parseText, VTTCue, VTTRegion }) => {
        if (init.type === "json") {
          this._parseJSON(init.content, VTTCue, VTTRegion);
        } else {
          parseText(init.content, { type: init.type }).then(({ cues, regions }) => {
            this._cues = cues;
            this._regions = regions;
            this._readyState();
          });
        }
      });
    } else if (!init.src)
      this[TEXT_TRACK_READY_STATE] = 2;
    if (isTrackCaptionKind(this) && !this.label) {
      throw Error(`[vidstack]: captions text track created without label: \`${this.src}\``);
    }
  }
  static createId(track) {
    return `id::${track.type}-${track.kind}-${track.src ?? track.label}`;
  }
  get metadata() {
    return this._metadata;
  }
  get regions() {
    return this._regions;
  }
  get cues() {
    return this._cues;
  }
  get activeCues() {
    return this._activeCues;
  }
  /**
   * - 0: Not Loading
   * - 1: Loading
   * - 2: Ready
   * - 3: Error
   */
  get readyState() {
    return this[TEXT_TRACK_READY_STATE];
  }
  get mode() {
    return this._mode;
  }
  set mode(mode) {
    this.setMode(mode);
  }
  addCue(cue, trigger) {
    let i = 0, length = this._cues.length;
    for (i = 0; i < length; i++)
      if (cue.endTime <= this._cues[i].startTime)
        break;
    if (i === length)
      this._cues.push(cue);
    else
      this._cues.splice(i, 0, cue);
    if (trigger?.type !== "cuechange") {
      this[TEXT_TRACK_NATIVE]?.track.addCue(cue);
    }
    this.dispatchEvent(new DOMEvent("add-cue", { detail: cue, trigger }));
    if (isCueActive(cue, this._currentTime)) {
      this[TEXT_TRACK_UPDATE_ACTIVE_CUES](this._currentTime, trigger);
    }
  }
  removeCue(cue, trigger) {
    const index = this._cues.indexOf(cue);
    if (index >= 0) {
      const isActive = this._activeCues.includes(cue);
      this._cues.splice(index, 1);
      this[TEXT_TRACK_NATIVE]?.track.removeCue(cue);
      this.dispatchEvent(new DOMEvent("remove-cue", { detail: cue, trigger }));
      if (isActive) {
        this[TEXT_TRACK_UPDATE_ACTIVE_CUES](this._currentTime, trigger);
      }
    }
  }
  setMode(mode, trigger) {
    if (this._mode === mode)
      return;
    this._mode = mode;
    if (mode === "disabled") {
      this._activeCues = [];
      this._activeCuesChanged();
    } else {
      this._load();
    }
    this.dispatchEvent(new DOMEvent("mode-change", { detail: this, trigger }));
    this[TEXT_TRACK_ON_MODE_CHANGE]?.();
  }
  /* @internal */
  [(_a = TEXT_TRACK_READY_STATE, _b = TEXT_TRACK_ON_MODE_CHANGE, _c = TEXT_TRACK_NATIVE, TEXT_TRACK_UPDATE_ACTIVE_CUES)](currentTime, trigger) {
    this._currentTime = currentTime;
    if (this.mode === "disabled" || !this._cues.length)
      return;
    const activeCues = [];
    for (let i = 0, length = this._cues.length; i < length; i++) {
      const cue = this._cues[i];
      if (isCueActive(cue, currentTime))
        activeCues.push(cue);
    }
    let changed = activeCues.length !== this._activeCues.length;
    if (!changed) {
      for (let i = 0; i < activeCues.length; i++) {
        if (!this._activeCues.includes(activeCues[i])) {
          changed = true;
          break;
        }
      }
    }
    this._activeCues = activeCues;
    if (changed)
      this._activeCuesChanged(trigger);
  }
  /* @internal */
  [TEXT_TRACK_CAN_LOAD]() {
    this._canLoad = true;
    if (this._mode !== "disabled")
      this._load();
  }
  async _load() {
    if (!this._canLoad || !this.src || this[TEXT_TRACK_READY_STATE] > 0)
      return;
    this[TEXT_TRACK_READY_STATE] = 1;
    this.dispatchEvent(new DOMEvent("load-start"));
    try {
      const { parseResponse, VTTCue, VTTRegion } = await import('./dev-DOQY4JGU.js'), crossorigin = this[TEXT_TRACK_CROSSORIGIN]?.();
      const response = fetch(this.src, {
        headers: this.type === "json" ? { "Content-Type": "application/json" } : void 0,
        credentials: getRequestCredentials(crossorigin)
      });
      if (this.type === "json") {
        this._parseJSON(await (await response).text(), VTTCue, VTTRegion);
      } else {
        const { errors, metadata, regions, cues } = await parseResponse(response, {
          type: this.type,
          encoding: this.encoding
        });
        if (errors[0]?.code === 0) {
          throw errors[0];
        } else {
          this._metadata = metadata;
          this._regions = regions;
          this._cues = cues;
        }
      }
      this._readyState();
    } catch (error) {
      this._errorState(error);
    }
  }
  _readyState() {
    this[TEXT_TRACK_READY_STATE] = 2;
    const nativeTrack = this[TEXT_TRACK_NATIVE]?.track;
    if (nativeTrack)
      for (const cue of this._cues)
        nativeTrack.addCue(cue);
    const loadEvent = new DOMEvent("load");
    this[TEXT_TRACK_UPDATE_ACTIVE_CUES](this._currentTime, loadEvent);
    this.dispatchEvent(loadEvent);
  }
  _errorState(error) {
    this[TEXT_TRACK_READY_STATE] = 3;
    this.dispatchEvent(new DOMEvent("error", { detail: error }));
  }
  _parseJSON(json, VTTCue, VTTRegion) {
    try {
      json = JSON.parse(json);
      if (json.regions) {
        this._regions = json.regions.map((json2) => Object.assign(new VTTRegion(), json2));
      }
      if (json.cues) {
        this._cues = json.cues.filter((json2) => isNumber(json2.startTime) && isNumber(json2.endTime)).map((json2) => Object.assign(new VTTCue(0, 0, ""), json2));
      }
    } catch (error) {
      {
        console.error(`[vidstack] failed to parse JSON captions at: \`${this.src}\`

`, error);
      }
      this._errorState(error);
    }
  }
  _activeCuesChanged(trigger) {
    this.dispatchEvent(new DOMEvent("cue-change", { trigger }));
  }
};
var captionRE = /captions|subtitles/;
function isTrackCaptionKind(track) {
  return captionRE.test(track.kind);
}

// src/player/core/providers/video/native-hls-text-tracks.ts
var NativeHLSTextTracks = class {
  constructor(_video, _context) {
    this._video = _video;
    this._context = _context;
    _video.textTracks.onaddtrack = this._onAddTrack.bind(this);
    onDispose(this._onDispose.bind(this));
  }
  _onAddTrack(event2) {
    const nativeTrack = event2.track;
    if (!nativeTrack || findTextTrackElement(this._video, nativeTrack))
      return;
    const track = new TextTrack({
      id: nativeTrack.id,
      kind: nativeTrack.kind,
      label: nativeTrack.label,
      language: nativeTrack.language,
      type: "vtt"
    });
    track[TEXT_TRACK_NATIVE] = { track: nativeTrack };
    track[TEXT_TRACK_READY_STATE] = 2;
    track[TEXT_TRACK_NATIVE_HLS] = true;
    let lastIndex = 0;
    const onCueChange = (event3) => {
      if (!nativeTrack.cues)
        return;
      for (let i = lastIndex; i < nativeTrack.cues.length; i++) {
        track.addCue(nativeTrack.cues[i], event3);
        lastIndex++;
      }
    };
    onCueChange(event2);
    nativeTrack.oncuechange = onCueChange;
    this._context.textTracks.add(track, event2);
    track.setMode(nativeTrack.mode, event2);
  }
  _onDispose() {
    this._video.textTracks.onaddtrack = null;
    for (const track of this._context.textTracks) {
      const nativeTrack = track[TEXT_TRACK_NATIVE]?.track;
      if (nativeTrack?.oncuechange)
        nativeTrack.oncuechange = null;
    }
  }
};
function findTextTrackElement(video, track) {
  return Array.from(video.children).find((el) => el.track === track);
}

// src/player/core/providers/video/picture-in-picture.ts
var VideoPictureInPicture = class {
  constructor(_video, _media) {
    this._video = _video;
    this._media = _media;
    this._onChange = (active, event2) => {
      this._media.delegate._dispatch("picture-in-picture-change", {
        detail: active,
        trigger: event2
      });
    };
    listenEvent(this._video, "enterpictureinpicture", this._onEnter.bind(this));
    listenEvent(this._video, "leavepictureinpicture", this._onExit.bind(this));
  }
  get active() {
    return document.pictureInPictureElement === this._video;
  }
  get supported() {
    return canUsePictureInPicture(this._video);
  }
  async enter() {
    return this._video.requestPictureInPicture();
  }
  exit() {
    return document.exitPictureInPicture();
  }
  _onEnter(event2) {
    this._onChange(true, event2);
  }
  _onExit(event2) {
    this._onChange(false, event2);
  }
};

// src/player/core/providers/video/presentation/video-presentation.ts
var VideoPresentation = class {
  constructor(_video, _media) {
    this._video = _video;
    this._media = _media;
    this._mode = "inline";
    listenEvent(this._video, "webkitpresentationmodechanged", this._onModeChange.bind(this));
  }
  get _supported() {
    return canUseVideoPresentation(this._video);
  }
  async _setPresentationMode(mode) {
    if (this._mode === mode)
      return;
    this._video.webkitSetPresentationMode(mode);
  }
  _onModeChange() {
    const prevMode = this._mode;
    this._mode = this._video.webkitPresentationMode;
    {
      this._media.logger?.infoGroup("presentation mode change").labelledLog("Mode", this._mode).labelledLog("Event", event).dispatch();
    }
    this._media.player?.dispatchEvent(
      new DOMEvent("video-presentation-change", {
        detail: this._mode,
        trigger: event
      })
    );
    ["fullscreen", "picture-in-picture"].forEach((type) => {
      if (this._mode === type || prevMode === type) {
        this._media.delegate._dispatch(`${type}-change`, {
          detail: this._mode === type,
          trigger: event
        });
      }
    });
  }
};
var FullscreenPresentationAdapter = class {
  constructor(_presentation) {
    this._presentation = _presentation;
  }
  get active() {
    return this._presentation._mode === "fullscreen";
  }
  get supported() {
    return this._presentation._supported;
  }
  async enter() {
    this._presentation._setPresentationMode("fullscreen");
  }
  async exit() {
    this._presentation._setPresentationMode("inline");
  }
};
var PIPPresentationAdapter = class {
  constructor(_presentation) {
    this._presentation = _presentation;
  }
  get active() {
    return this._presentation._mode === "picture-in-picture";
  }
  get supported() {
    return this._presentation._supported;
  }
  async enter() {
    this._presentation._setPresentationMode("picture-in-picture");
  }
  async exit() {
    this._presentation._setPresentationMode("inline");
  }
};

// src/player/core/providers/video/provider.ts
var VIDEO_PROVIDER = Symbol("VIDEO_PROVIDER" );
var _a2;
var VideoProvider = class extends HTMLMediaProvider {
  constructor(video, context) {
    super(video);
    this[_a2] = true;
    if (canUseVideoPresentation(video)) {
      const presentation = new VideoPresentation(video, context);
      this.fullscreen = new FullscreenPresentationAdapter(presentation);
      this.pictureInPicture = new PIPPresentationAdapter(presentation);
    } else if (canUsePictureInPicture(video)) {
      this.pictureInPicture = new VideoPictureInPicture(video, context);
    }
  }
  get type() {
    return "video";
  }
  setup(context) {
    super.setup(context);
    if (canPlayHLSNatively(this.video)) {
      new NativeHLSTextTracks(this.video, context);
    }
    context.textRenderers[ATTACH_VIDEO](this.video);
    onDispose(() => {
      context.textRenderers[ATTACH_VIDEO](null);
    });
    if (this.type === "video")
      context.delegate._dispatch("provider-setup", { detail: this });
  }
  /**
   * The native HTML `<video>` element.
   *
   * @see {@link https://developer.mozilla.org/en-US/docs/Web/API/HTMLVideoElement}
   */
  get video() {
    return this._media;
  }
};
_a2 = VIDEO_PROVIDER;

export { ATTACH_VIDEO, TEXT_TRACK_CAN_LOAD, TEXT_TRACK_CROSSORIGIN, TEXT_TRACK_NATIVE, TEXT_TRACK_NATIVE_HLS, TEXT_TRACK_ON_MODE_CHANGE, TEXT_TRACK_READY_STATE, TEXT_TRACK_UPDATE_ACTIVE_CUES, TextTrack, VIDEO_PROVIDER, VideoProvider, findActiveCue, getRequestCredentials, isCueActive, isTrackCaptionKind, loadScript, onTrackChapterChange, preconnect };
